 so then tim peters is all like guido i don t know how big that pickle would be maybe loading it each time is fine or maybe marshalling my tests train on about msgs and a binary pickle of the database is approaching million bytes my paltry message training set makes a mb where mb e bytes pickle hammie py which i just checked in will optionally let you write stuff out to a dbm file with that same message base the dbm file weighs in at a hefty mb it also takes longer to write using a database real m s user m s sys m s using a pickle real m s user m s sys m s this is on a piii at mhz i don t know what it s supposed to be is what proc cpuinfo says for comparison spamoracle currently the gold standard in my mind at least for speed on the same data blazes along real m s user m s sys m s its data file which appears to be a marshalled hash is kb however it s compiled o caml and it uses a much simpler tokenizing algorithm written with a lexical analyzer ocamllex so we ll never be able to outperform it it s something to keep in mind though i don t have statistics yet for scanning unknown messages actually i do and the database blows the pickle out of the water but it scores every word with so i m not sure that s a fair test in any case mb per user is probably too large and mb is questionable on the other hand my pickle compressed very well with gzip shrinking down to mb neale 