 anthony baxter well i ve finally got around to pulling down the sf code starting with it and absolutely zero local modifications i see the following how many runs is this summarizing for each how many ham spam were in the training set how many in the prediction sets what were the error rates run rates py over your output file the effect of set sizes on accuracy rates isn t known i ve informally reported some results from just a few controlled experiments on that jeremy reported improved accuracy by doubling the training set size but that wasn t a controlled experiment things besides just training set size changed between before and after ham distribution for all runs items spam distribution for all runs items my next current task is to complete the corpus i ve got it s currently got ham spam and about currently unsorted i m tossing up using either hammie or spamassassin to do the initial sort previously i ve used various forms of grep for keywords and a little gui thing to pop a message up and let me say spam ham but that s just getting too too tedious yup tagging data is mondo tedious and mistakes hurt i expect hammie will do a much better job on this already than hand grepping be sure to stare at the false positives and get the spam out of there i can t make it available en masse but i will look at finding some of the more interesting uglies one thing i ve seen consider this anecdotal for now is that the skip tokens end up in a lot of the f ps with probabilities favoring ham or spam a skip token is produced in lieu of word more than chars long and without any high bit characters it s possible that they helped me because raw html produces lots of these however if you re running current cvs tokenizer retain pure html tags defaults to false now so html decorations should vanish before body tokenization 